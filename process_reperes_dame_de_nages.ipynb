{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process_reperes_dame_de_nages",
      "provenance": [],
      "authorship_tag": "ABX9TyNdKH1Mq6CrqroAdq0neNvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evaie/evaie/blob/main/process_reperes_dame_de_nages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKcTDp9NsHWx"
      },
      "source": [
        "#Get references data\n",
        "Find Mattieu's file and read it into a dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rsDYrFr8GR"
      },
      "source": [
        "# piece of code that get a token\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# authenticate the user\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHlhhC2IwO6K"
      },
      "source": [
        "Once authenticated, list the files that contains personal records for the atheletes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmM_u1sywXSy",
        "outputId": "03fc9ecd-f933-4911-faa8-0a59b56e8aa4"
      },
      "source": [
        "# Auto-iterate through all files that matches this query\n",
        "#file_list = drive.ListFile({'q': \"'root' in parents and title contains 'Champs' and trashed=false\"}).GetList()\n",
        "#sharedWithMe=true \n",
        "# id = 1VJMXVNSxIv4li8yK7pXZ3sitWEdC8z-93z_Apkl77_Q\n",
        "file_list = drive.ListFile({'q': \"sharedWithMe=true and trashed=false and title contains '2021 - repères d'\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: 2021 - repères d'intensité, id: 1VJMXVNSxIv4li8yK7pXZ3sitWEdC8z-93z_Apkl77_Q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAvSnNJI_BCJ"
      },
      "source": [
        "once the id of the spreadsheet retrieved, load it. \n",
        "But first, we need to be allowed Gspread  / GSheet to access to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHdv2xxc_KEd"
      },
      "source": [
        "# piece of code that get a token\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxxEFhZpOfzB"
      },
      "source": [
        "Then load, the data into a dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o1K8HxjQ_68"
      },
      "source": [
        "sh = gc.open_by_key('1VJMXVNSxIv4li8yK7pXZ3sitWEdC8z-93z_Apkl77_Q')\n",
        "worksheet = sh.get_worksheet(0)\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "#print(rows)\n",
        "\n",
        "import pandas as pd\n",
        "df_reperes = pd.DataFrame.from_records(rows)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NMEvXueWRlb"
      },
      "source": [
        "Reprocess the dataframe : renaming the columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "7WGqBH9GJEIJ",
        "outputId": "40ee03fd-90d8-4345-d994-797d56274b38"
      },
      "source": [
        "df_reperes\n",
        "# column names un 1st row\n",
        "# reformat\n",
        "headers = df_reperes.iloc[0].apply(lambda x: str(x).replace(' ', '_'))\n",
        "headers = headers.apply(lambda x: str(x).replace('(', ''))\n",
        "headers = headers.apply(lambda x: str(x).replace(')', ''))\n",
        "headers = headers.apply(lambda x: str(x).replace('.', ''))\n",
        "headers = headers.apply(lambda x: str(x).replace('é', 'e'))\n",
        "headers = headers.apply(lambda x: str(x).replace('_/_', '_'))\n",
        "headers = headers.apply(lambda x: str(x).replace(',', '_'))\n",
        "headers = headers.apply(lambda x: str(x).lower())\n",
        "\n",
        "# rename columns\n",
        "df_reperes = df_reperes.rename(columns=headers)\n",
        "df_reperes = df_reperes.drop(0)\n",
        "df_reperes"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nom</th>\n",
              "      <th>prenom</th>\n",
              "      <th>categorie</th>\n",
              "      <th>record_ergo</th>\n",
              "      <th>distance</th>\n",
              "      <th>sec_500</th>\n",
              "      <th>watts</th>\n",
              "      <th>objectif_watts_bateau_0_85</th>\n",
              "      <th>ftp</th>\n",
              "      <th>watts_b1</th>\n",
              "      <th>watts_b2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Boccanfuso</td>\n",
              "      <td>Inès</td>\n",
              "      <td>SFPL</td>\n",
              "      <td>07:22,50</td>\n",
              "      <td>2000</td>\n",
              "      <td>110,63</td>\n",
              "      <td>259</td>\n",
              "      <td>220</td>\n",
              "      <td></td>\n",
              "      <td>132</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morizot</td>\n",
              "      <td>Aurélie</td>\n",
              "      <td>SFPL</td>\n",
              "      <td>07:15,00</td>\n",
              "      <td>2000</td>\n",
              "      <td>108,75</td>\n",
              "      <td>272</td>\n",
              "      <td>231</td>\n",
              "      <td></td>\n",
              "      <td>139</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Quenneville</td>\n",
              "      <td>Florian</td>\n",
              "      <td>SHTC</td>\n",
              "      <td>06:16,50</td>\n",
              "      <td>2000</td>\n",
              "      <td>94,13</td>\n",
              "      <td>420</td>\n",
              "      <td>357</td>\n",
              "      <td></td>\n",
              "      <td>214</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gely</td>\n",
              "      <td>Axel</td>\n",
              "      <td>SHTC</td>\n",
              "      <td>06:31,80</td>\n",
              "      <td>2000</td>\n",
              "      <td>97,95</td>\n",
              "      <td>372</td>\n",
              "      <td>317</td>\n",
              "      <td></td>\n",
              "      <td>190</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>De Villers</td>\n",
              "      <td>Louis</td>\n",
              "      <td>SHPL</td>\n",
              "      <td>06:39,90</td>\n",
              "      <td>2000</td>\n",
              "      <td>99,98</td>\n",
              "      <td>350</td>\n",
              "      <td>298</td>\n",
              "      <td></td>\n",
              "      <td>179</td>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ferrière</td>\n",
              "      <td>Mathys</td>\n",
              "      <td>SHPL</td>\n",
              "      <td>06:34,00</td>\n",
              "      <td>2000</td>\n",
              "      <td>98,50</td>\n",
              "      <td>366</td>\n",
              "      <td>311</td>\n",
              "      <td></td>\n",
              "      <td>187</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Schwendenwein</td>\n",
              "      <td>Vincent</td>\n",
              "      <td>SHTC</td>\n",
              "      <td>06:34,50</td>\n",
              "      <td>2000</td>\n",
              "      <td>98,63</td>\n",
              "      <td>365</td>\n",
              "      <td>310</td>\n",
              "      <td></td>\n",
              "      <td>186</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macre</td>\n",
              "      <td>Philippe</td>\n",
              "      <td>SHTC</td>\n",
              "      <td>06:44,20</td>\n",
              "      <td>2000</td>\n",
              "      <td>101,05</td>\n",
              "      <td>339</td>\n",
              "      <td>288</td>\n",
              "      <td></td>\n",
              "      <td>173</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Dore</td>\n",
              "      <td>Maxime</td>\n",
              "      <td>SHPL</td>\n",
              "      <td>06:40,60</td>\n",
              "      <td>2000</td>\n",
              "      <td>100,15</td>\n",
              "      <td>348</td>\n",
              "      <td>296</td>\n",
              "      <td></td>\n",
              "      <td>178</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Le Levreur</td>\n",
              "      <td>Jean</td>\n",
              "      <td>SHPL</td>\n",
              "      <td>06:47,00</td>\n",
              "      <td>2000</td>\n",
              "      <td>101,75</td>\n",
              "      <td>332</td>\n",
              "      <td>282</td>\n",
              "      <td></td>\n",
              "      <td>169</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Marchal</td>\n",
              "      <td>Louis</td>\n",
              "      <td>J18H</td>\n",
              "      <td>06:37,10</td>\n",
              "      <td>2000</td>\n",
              "      <td>99,28</td>\n",
              "      <td>358</td>\n",
              "      <td>304</td>\n",
              "      <td></td>\n",
              "      <td>182</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Lecomte</td>\n",
              "      <td>Adrien</td>\n",
              "      <td>J18H</td>\n",
              "      <td>06:38,70</td>\n",
              "      <td>2000</td>\n",
              "      <td>99,68</td>\n",
              "      <td>353</td>\n",
              "      <td>300</td>\n",
              "      <td></td>\n",
              "      <td>180</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bara Butez</td>\n",
              "      <td>Yohan</td>\n",
              "      <td>J18H</td>\n",
              "      <td>06:29,20</td>\n",
              "      <td>2000</td>\n",
              "      <td>97,30</td>\n",
              "      <td>380</td>\n",
              "      <td>323</td>\n",
              "      <td></td>\n",
              "      <td>194</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              nom    prenom categorie  ... ftp watts_b1 watts_b2\n",
              "1      Boccanfuso      Inès      SFPL  ...          132      165\n",
              "2         Morizot   Aurélie      SFPL  ...          139      173\n",
              "3     Quenneville   Florian      SHTC  ...          214      268\n",
              "4            Gely      Axel      SHTC  ...          190      237\n",
              "5     De Villers      Louis      SHPL  ...          179      223\n",
              "6        Ferrière    Mathys      SHPL  ...          187      233\n",
              "7   Schwendenwein   Vincent      SHTC  ...          186      233\n",
              "8           Macre  Philippe      SHTC  ...          173      216\n",
              "9            Dore    Maxime      SHPL  ...          178      222\n",
              "10    Le Levreur       Jean      SHPL  ...          169      212\n",
              "11        Marchal     Louis      J18H  ...          182      228\n",
              "12       Lecomte     Adrien      J18H  ...          180      225\n",
              "13     Bara Butez     Yohan      J18H  ...          194      242\n",
              "\n",
              "[13 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Jeqyi8eGCi"
      },
      "source": [
        "# Get the data from the outriggers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ddL5otne9Wq",
        "outputId": "25142752-db09-404d-8621-7b4ba824bebe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# files whose title contains SpdCoach and not in the trash\n",
        "file_list = drive.ListFile({'q': \"title contains 'SpdCoach' and trashed=false\"}).GetList()\n",
        "ddd_list = list()\n",
        "for ddd_file in file_list:\n",
        "  # collect meta data from the filename\n",
        "  filename = ddd_file['title']\n",
        "  file_id = ddd_file['id']\n",
        "  tokens = filename.split('-')\n",
        "  rower = tokens[1].strip()\n",
        "  training_type = tokens[2].split('.')[0].strip()\n",
        "  date = tokens[0].split(' ')[2].strip() +':'+ tokens[0].split(' ')[3].strip()\n",
        "  print('rower: %s, training type: %s, date: %s' % (rower, training_type, date))\n",
        "  \n",
        "  # this assume pyDrive has a token to read the GoogleDrive\n",
        "  myfile = drive.CreateFile({'id': file_id})\n",
        "  myfile.GetContentFile('file.csv')\n",
        "  \n",
        "  # then read it in a Dataframe\n",
        "  ddd = pd.read_csv('file.csv', skiprows=27, header=None)\n",
        "\n",
        "  # clean and organize the data\n",
        "  # column names un 1st row\n",
        "  # reformat\n",
        "  headers = ddd.iloc[0].apply(lambda x: str(x).replace(' ', '_'))\n",
        "  headers = headers.apply(lambda x: str(x).replace('(', ''))\n",
        "  headers = headers.apply(lambda x: str(x).replace(')', ''))\n",
        "  headers = headers.apply(lambda x: str(x).replace('.', ''))\n",
        "  headers = headers.apply(lambda x: str(x).lower())\n",
        "\n",
        "  # rename columns\n",
        "  ddd = ddd.rename(columns=headers)\n",
        "\n",
        "  # dropping NA values\n",
        "  ddd2 = ddd.dropna()\n",
        "\n",
        "  # drop the 2 first lines\n",
        "  ddd2 = ddd2.drop([0, 1])\n",
        "\n",
        "  # drop the 2 last rows\n",
        "  #ddd2 = ddd2.drop(ddd2.tail(2).index)\n",
        "\n",
        "  # reset the index\n",
        "  ddd2 = ddd2.reset_index(drop=True)\n",
        "\n",
        "  # changing column types\n",
        "  column_names = list(ddd2.columns)\n",
        "\n",
        "  # datetime columns\n",
        "  # remove lines with date time columns formated to '---'\n",
        "  ddd2 = ddd2.drop(ddd2[ddd2['elapsed_time'].map(lambda x: str(x) == '---')].index)\n",
        "  ddd2 = ddd2.drop(ddd2[ddd2['split_gps'].map(lambda x: str(x) == '---')].index)\n",
        "  ddd2 = ddd2.drop(ddd2[ddd2['split_imp'].map(lambda x: str(x) == '---')].index)\n",
        "\n",
        "  # iterating on columns and change the types to string\n",
        "  for col in column_names:\n",
        "      ddd2[col] = ddd2[col].apply(lambda x: str(x).replace('---', '0'))\n",
        "\n",
        "  ddd2 = ddd2.convert_dtypes()\n",
        "\n",
        "  # removing datetime columns from the columns list\n",
        "  column_names.pop(3)  # 'elapsed_time'\n",
        "  column_names.pop(3)  # 'split_gps'\n",
        "  column_names.pop(4)  # 'split_imp'\n",
        "\n",
        "  # add meta data\n",
        "  ddd2['rower'] = rower\n",
        "  ddd2['training_type'] = training_type\n",
        "  ddd2['date'] = date\n",
        "\n",
        "  for col in column_names:\n",
        "    ddd2[col] = pd.to_numeric(ddd2[col])\n",
        "\n",
        "  # accumulate ddd\n",
        "  ddd_list.append(ddd2)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rower: Adrien, training type: 500 et recup, date: 20210403:0814am\n",
            "rower: Louis, training type: 500, date: 20210403:0814am\n",
            "rower: Louis, training type: recup, date: 20210403:0824am\n",
            "rower: Louis, training type: 1000, date: 20210331:0420pm\n",
            "rower: Adrien, training type: 1000, date: 20210331:0420pm\n",
            "rower: Yohan, training type: 1000, date: 20210331:0253pm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwVnTWAxcmSU"
      },
      "source": [
        "# concat dataframes\n",
        "all_ddd = pd.concat(ddd_list)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLZ9ptL3YHy1"
      },
      "source": [
        "Save the reperes worksheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VepKo4jmp7OI"
      },
      "source": [
        "import gspread\n",
        "import gspread_dataframe as gd\n",
        "\n",
        "# this piece of code assumes we already have a token to read / write a Google Sheet\n",
        "# 1e_ThufABmmmbUlqQ05VoCrXfChhDuQHMnZQMYw73NxA is the id of DameDeNage_database\n",
        "db_sh = gc.open_by_key('1e_ThufABmmmbUlqQ05VoCrXfChhDuQHMnZQMYw73NxA')\n",
        "\n",
        "wsheet = db_sh.worksheet('reperes')\n",
        "gd.set_with_dataframe(wsheet,df_reperes)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p31JzST2GTg4"
      },
      "source": [
        "Adding a workseet with the dame de nage data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX8Q04tMH7yO"
      },
      "source": [
        "import gspread\n",
        "import gspread_dataframe as gd\n",
        "\n",
        "# this piece of code assumes we already have a token to read / write a Google Sheet\n",
        "# 1e_ThufABmmmbUlqQ05VoCrXfChhDuQHMnZQMYw73NxA is the id of DameDeNage_database\n",
        "db_sh = gc.open_by_key('1e_ThufABmmmbUlqQ05VoCrXfChhDuQHMnZQMYw73NxA')\n",
        "\n",
        "\n",
        "worksheet_data = db_sh.worksheet('data')\n",
        "gd.set_with_dataframe(worksheet_data,all_ddd)"
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}